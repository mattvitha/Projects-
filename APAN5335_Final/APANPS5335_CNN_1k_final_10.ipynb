{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train/=255\n",
    "X_test/=255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = 10\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, number_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[0:1000]\n",
    "Y_train = Y_train[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three steps to create a CNN\n",
    "# 1. Convolution\n",
    "# 2. Activation\n",
    "# 3. Pooling\n",
    "# Repeat Steps 1,2,3 for adding more hidden layers\n",
    "\n",
    "# 4. After that make a fully connected network\n",
    "# This fully connected network gives ability to the CNN\n",
    "# to classify the samples\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                         height_shift_range=0.08, zoom_range=0.08)\n",
    "\n",
    "test_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = gen.flow(X_train, Y_train, batch_size=64)\n",
    "test_generator = test_gen.flow(X_test, Y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "937/937 [==============================] - 183s 196ms/step - loss: 0.0621 - accuracy: 0.9818 - val_loss: 0.0366 - val_accuracy: 0.9753\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 187s 199ms/step - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.0082 - val_accuracy: 0.9749\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 188s 201ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.2601 - val_accuracy: 0.9760\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 177s 189ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0650 - val_accuracy: 0.9646\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 176s 188ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.1151 - val_accuracy: 0.9775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x64a8b22e8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=5, \n",
    "                    validation_data=test_generator, validation_steps=10000//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 560us/step\n",
      "\n",
      "Test accuracy:  0.977400004863739\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print()\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'activations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-6522078ac1f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlayer_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimages_per_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_activation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_activation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'activations' is not defined"
     ]
    }
   ],
   "source": [
    "layer_names = []\n",
    "for layer in model.layers[:-1]:\n",
    "    layer_names.append(layer.name) \n",
    "images_per_row = 16\n",
    "for layer_name, layer_activation in zip(layer_names, activations):\n",
    "    if layer_name.startswith('conv'):\n",
    "        n_features = layer_activation.shape[-1]\n",
    "        size = layer_activation.shape[1]\n",
    "        n_cols = n_features // images_per_row\n",
    "        display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "        for col in range(n_cols):\n",
    "            for row in range(images_per_row):\n",
    "                channel_image = layer_activation[0,:, :, col * images_per_row + row]\n",
    "                channel_image -= channel_image.mean()\n",
    "                channel_image /= channel_image.std()\n",
    "                channel_image *= 64\n",
    "                channel_image += 128\n",
    "                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "                display_grid[col * size : (col + 1) * size,\n",
    "                             row * size : (row + 1) * size] = channel_image\n",
    "        scale = 1. / size\n",
    "        plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                            scale * display_grid.shape[0]))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 597,738\n",
      "Trainable params: 596,330\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_im = X_train[154]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"co..., outputs=[<tf.Tenso...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x63c86bd30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras import models\n",
    "layer_outputs = [layer.output for layer in model.layers[:8]]\n",
    "activation_model = models.Model(input=model.input, output=layer_outputs)\n",
    "activations = activation_model.predict(test_im.reshape(1,28,28,1))\n",
    "\n",
    "first_layer_activation = activations[0]\n",
    "plt.matshow(first_layer_activation[0, :, :, 4], cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
